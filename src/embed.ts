import fs from 'fs'
import path from 'path'
import pdfParse from "pdf-parse"
import { parse } from 'csv-parse/sync';
import { MDocument } from "@mastra/rag";
import { embedMany } from 'ai';
import { openai } from '@ai-sdk/openai';
import { mastra } from "./mastra";
import { getChunkOptionsForExtension } from './utils/chunking';
import 'dotenv/config';

/**
 * å…¥åŠ›ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«åŸºã¥ãã€ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¨®é¡ã”ã¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°ã€‚
 * - PDF: ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆpdf-parseï¼‰
 * - CSV: å„è¡Œã‚’ã‚¹ãƒšãƒ¼ã‚¹çµåˆã—ã¦ã¾ã¨ã‚ã‚‹
 *
 * @param filePath ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆ.pdf ã¾ãŸã¯ .csvï¼‰
 * @returns ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—
 */
async function extractTextFromFile(filePath: string) {
  const ext = path.extname(filePath).toLowerCase();
  const buffer = fs.readFileSync(filePath);

  switch (ext) {
    case ".pdf":
      const data = await pdfParse(buffer);
      return { text: data.text, ext };
    case ".csv":
      const csvContent = buffer.toString('utf-8');
      const records: any[] = parse(csvContent, { columns: true });
      const text = records.map(record  => Object.values(record).join(' ')).join('\n\n');
      return { text, ext };
    default:
      throw new Error(`Unsupported file type: ${ext}`);
  }
}

/**
 * ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã—ã€åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¦Qdrantã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°ã€‚
 *
 * @param rawText å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆPDFã‚„CSVã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚‚ã®ï¼‰
 * @param indexName Qdrantä¸Šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åï¼ˆä¿å­˜å…ˆã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
 */
async function uploadTextToQdrant(rawText: string, ext: string, indexName: string, filename: string) {
  const doc = new MDocument({
    docs: [{ text: rawText }],
    type: 'plain',
  });

  const chunkOptions = getChunkOptionsForExtension(ext);
  const chunks = await doc.chunk(chunkOptions)

  const { embeddings } = await embedMany({
    model: openai.embedding('text-embedding-3-small'),
    values: chunks.map(chunk => chunk.text),
  });

  const vectorStore = mastra.getVector('qdrantVector');

  const indexes = await vectorStore.listIndexes();
  if (!indexes.includes(indexName)) {
    await vectorStore.createIndex({
      indexName: indexName,
      dimension: 1536,
    });
  } else {
    console.log(`âœ… Index '${indexName}' already exists. Skipping creation.`);
  }

  await vectorStore.upsert({
    indexName: indexName,
    vectors: embeddings,
    metadata: chunks.map(chunk => ({
      text: chunk.text,
      source: filename,
    })),
  });

  console.log(`âœ… ${embeddings.length} ä»¶ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ Qdrant ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†`);
}

// ========================== CLIå®Ÿè¡Œéƒ¨ ==========================

const args = process.argv.slice(2);
if (args.length < 2) {
  console.error('Usage: npm run embed -- sample.pdf index-name');
  process.exit(1);
}

const [filename, indexName] = args;
// ./documents ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡ã¨ã™ã‚‹
const resolvedPath = path.resolve('documents', filename);
console.log('ğŸ“„ èª­ã¿è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«:', resolvedPath);

extractTextFromFile(resolvedPath)
  .then(({ text, ext }) => uploadTextToQdrant(text, ext, indexName, filename))
  .catch(err => {
    console.error('âŒ ã‚¨ãƒ©ãƒ¼:', err);
    process.exit(1);
  });